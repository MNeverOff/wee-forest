{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating erroneous areas\n",
    "\n",
    "As par the [uk_gb_nfi_geospatial](uk_gb_nfi_geospatial.ipynb) notebook, we are running a risk of getting inexplicable errors during overlay. To combat that, this compact notebook iterates over the NFI dataset in a memory-efficient way, using the NFI processing from the Geospatial and the AWI dataset.\n",
    "\n",
    "<details>\n",
    "    <summary>Details of the troubleshooting for future reference</summary>\n",
    "\n",
    "For the year of 2022 specifically, when overlaying the `Trees` type subset, the issue is caused by 2-3 geometries, bizarrely inconsistently, they are:\n",
    "- Wales, Pickle Wood, `Trees`, Index 461425, 51.7957357810459, -4.827321677247609, Area 41.147849, geometry `POLYGON ((204593.604 214909.751, 204593.800...`\n",
    "- Wales, Allt Rhosygilwen, `Trees`, Index 469005, 52.036802759545104, -4.617561294671731, Area 46.6604904321, geometry `POLYGON ((221343.140 241874.840, 221343.515...`\n",
    "- Wales, Coed y Brenin Forest, `Trees`, Index 537605, 52.815008884136546, -3.8724175720291303, Area 443.201233981, geometry `POLYGON ((272336.730 328993.532, 272343.858...`\n",
    "- Wales, Dulas Valley, `Barren & Felled`, Index 561434, 52.64613555533024, -3.8447860459273797, Area 52.889922, geometry `POLYGON ((275280.160 307096.420, 275280.860...`\n",
    "\n",
    "They are usually represented by the following error messages (`Trees` ones below):\n",
    "```python\n",
    "TopologyException: found non-noded intersection between LINESTRING (204841 214686, 204858 214683) and LINESTRING (204858 214683, 204841 214686) at 204846.78035594229 214685.10662104361\n",
    "TopologyException: found non-noded intersection between LINESTRING (273354 325793, 273352 325796) and LINESTRING (273352 325796, 273355 325793) at 273354.15382456378 325793.3069786204\n",
    "TopologyException: found non-noded intersection between LINESTRING (220596 240170, 220598 240169) and LINESTRING (220598 240169, 220596 240170) at 220595.98972291514 240169.62026441595 557750:557800\n",
    "```\n",
    "\n",
    "Simplifying them, usually to a tolerance of `1e-1` seems to be sufficient to make the overlay work. This segment of the workflow is designated to that procedure, specifically the `find_problematic_indices` function that recursively finds all problematic indices for further simplification. It's advised to start with `1e-5` and work down using the rule of .3, i.e. `1e-5`, `3e-4`, `1e-4` etc. to find the most precise simplified geometry that doesn't cause the error.\n",
    "\n",
    "Importantly, the errors would be different depending on which overlays one wants to perform, the `Trees` or `Barren & Felled` subset. Values for both are included for consistency, as the recursive function runs against the entire dataset as opposed to specific subsets to ensure it's full compliance.\n",
    "\n",
    "Lastly, important to note that `overlay=intersection` does not produce similar errors, but for these functions the simplified geometries will be used nonetheless for consistency.\n",
    "\n",
    "There are some invalid geometries in both AWI and NFI datasets, but if they are removed the resulting difference doesn't make sense. \"Fixing\" them with buffer(0) yielded no result either.\n",
    "\n",
    "![The culprit image](../assets/pickle_wood_dark.png)\n",
    "</details>\n",
    "\n",
    "### Notes\n",
    "\n",
    "All runtimes are indicated for Apple M1 Max 64GB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "gpd.options.io_engine = 'pyogrio'\n",
    "import concurrent.futures\n",
    "\n",
    "import util.geo_ops as gops\n",
    "\n",
    "from shapely import wkb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main recursive function to find problematic indices\n",
    "def find_problematic_indices(ldf, rdf, start, end, overlay_operation='difference'):\n",
    "    problematic_indices = []\n",
    "\n",
    "    if start > end:\n",
    "        return problematic_indices\n",
    "\n",
    "    mid = (start + end) // 2\n",
    "\n",
    "    try:\n",
    "        print(f'Checking midpoint {ldf.iloc[[mid]].index.item()}')\n",
    "        gpd.overlay(ldf.iloc[[mid]], rdf, how=overlay_operation, keep_geom_type=False)\n",
    "    except:\n",
    "        problematic_indices.append({'Indices': ldf.iloc[[mid]].index.item(), 'Tolerance': None})\n",
    "        print(f'Error found at midpoint {ldf.iloc[[mid]].index.item()}')\n",
    "\n",
    "    # Check the first half\n",
    "    try:\n",
    "        print(f'Checking the first half at {ldf.iloc[start:mid].index}')\n",
    "        gpd.overlay(ldf.iloc[start:mid], rdf, how=overlay_operation, keep_geom_type=False)\n",
    "        print(f'No errors in the first half at {ldf.iloc[start:mid].index}, moving to the second half.')\n",
    "    except:\n",
    "        print(f\"Error in the first half at {ldf.iloc[start:mid].index}\")\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            future = executor.submit(find_problematic_indices, ldf, rdf, start, mid, overlay_operation)\n",
    "            problematic_indices += future.result()\n",
    "\n",
    "    try:\n",
    "        print(f'Checking the second half at {ldf.iloc[mid:end + 1].index}')\n",
    "        gpd.overlay(ldf.iloc[mid:end + 1], rdf, how=overlay_operation, keep_geom_type=False)\n",
    "        print(f\"No errors in the second half at {ldf.iloc[mid:end + 1].index}, existing this layer of search.\")\n",
    "    except:\n",
    "        print(f\"Error in the second half, narrowing the search range.\")\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            future = executor.submit(find_problematic_indices, ldf, rdf, mid + 1, end, overlay_operation)\n",
    "            problematic_indices += future.result()\n",
    "\n",
    "    return problematic_indices\n",
    "\n",
    "def find_problematic_indices_main(left_df, right_df, type_column=None, type_value=None, problematic_indices=None, overlay_operation='difference'):\n",
    "    # Copy to avoid modifying the original DataFrame\n",
    "    ldf = left_df.copy()\n",
    "    rdf = right_df.copy()\n",
    "\n",
    "    # Simplify the geometries of the problematic indices if any\n",
    "    if problematic_indices is not None:\n",
    "        for idx, row in problematic_indices.iterrows():\n",
    "            if row['Indices'] in ldf.index:\n",
    "                ldf.loc[row['Indices'], 'geometry'] = ldf.loc[row['Indices'], 'geometry'].simplify(row['Tolerances'])\n",
    "        print(f'Simplified geometry for problematic indices at {problematic_indices[\"Indices\"].values} to tolerance {problematic_indices[\"Tolerances\"].values}')\n",
    "\n",
    "    # Filtering by type requested\n",
    "    if type_column is not None and type_value is not None:\n",
    "        ldf = ldf[ldf[type_column] == type_value]\n",
    "\n",
    "    # Initialize the search range\n",
    "    start, end = 0, len(ldf) - 1\n",
    "\n",
    "    print(f'Starting search from {start} to {end}')\n",
    "    problematic_indices = find_problematic_indices(ldf, rdf, start, end, overlay_operation)\n",
    "\n",
    "    return pd.DataFrame(problematic_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary function for crude debugging if a range is known within 100-ish indices\n",
    "def debug_overlay_datasets(left_df, right_df, type_column, type_value, index_range=None, drop_indices=None, overlay_operation='difference'):\n",
    "    # Drop specified indices if any, before filtering\n",
    "    ldf = left_df\n",
    "    if drop_indices is not None:\n",
    "        ldf = ldf.drop(drop_indices)\n",
    "\n",
    "    # Filter by index range if specified\n",
    "    if index_range is not None:\n",
    "        ldf = ldf.loc[index_range[0]:index_range[1]]\n",
    "\n",
    "    ldf = ldf[ldf[type_column] == type_value]\n",
    "    rdf = right_df\n",
    "\n",
    "    # Initialize overlay as an empty GeoDataFrame\n",
    "    overlay = gpd.GeoDataFrame()\n",
    "\n",
    "    # Iterate over each index in the range\n",
    "    for idx in ldf.index:\n",
    "        try:\n",
    "            # Use overlay to find the geometries in left_df_crs that do not intersect with right_df_crs\n",
    "            overlay_idx = gpd.overlay(ldf.loc[[idx]], rdf, how=overlay_operation, keep_geom_type=False)\n",
    "\n",
    "            print(f\"Success for index {idx}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error for index {idx}, area {ldf.loc[[idx]].area_ha}: {e}\")\n",
    "\n",
    "    return overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the AWI dataset from parquet\n",
    "# Runtime: 2s, RAM: 1.5GB\n",
    "df = pd.read_parquet('../data/processed/gb_awi_dataset.parquet')\n",
    "df['geometry'] = df['geometry'].apply(wkb.loads)\n",
    "awi_dataset = gpd.GeoDataFrame(df, geometry='geometry')\n",
    "awi_dataset = awi_dataset.set_crs(epsg=27700)\n",
    "gops.geodf_summary(awi_dataset, 'type_combined', 'area_ha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the NFI dataset from parquet\n",
    "# Runtime: 1m, RAM: 30GB\n",
    "nfi_dataset = {}\n",
    "\n",
    "for year in range(2012, 2023):\n",
    "    df = pd.read_parquet(f'../data/processed/gb_nfi_dataset_{year}.parquet')\n",
    "    df['geometry'] = df['geometry'].apply(wkb.loads)\n",
    "    gdf = gpd.GeoDataFrame(df, geometry='geometry')\n",
    "    gdf = gdf.set_crs(epsg=27700)\n",
    "    nfi_dataset[year] = gdf\n",
    "\n",
    "gops.geodfs_print_summary(nfi_dataset, 'type_combined', 'area_ha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runtime: 20m per year on average, 4h total, 40GB RAM peak\n",
    "problematic_indices = {}\n",
    "\n",
    "for year in range(2012, 2023):\n",
    "    print(f'Finished loading {year}, starting processing')\n",
    "    problematic_indices[year] = find_problematic_indices_main(nfi_dataset[year], awi_dataset, overlay_operation='difference')\n",
    "    print(f'Finished processing year {year}')\n",
    "\n",
    "problematic_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problematic_records_dict = {}\n",
    "\n",
    "for year, df in problematic_indices.items():\n",
    "    indices = df['Indices']\n",
    "    problematic_records = nfi_dataset[year].loc[indices]\n",
    "    problematic_records['year'] = year\n",
    "    problematic_records_dict[year] = problematic_records\n",
    "\n",
    "problematic_gdf = pd.concat(problematic_records_dict.values(), ignore_index=True)\n",
    "problematic_gdf = problematic_gdf.sort_values(['year', 'source_index'])\n",
    "\n",
    "cols = ['year'] + [col for col in problematic_gdf.columns if col != 'year']\n",
    "problematic_gdf = problematic_gdf[cols].reset_index(drop=True)\n",
    "\n",
    "problematic_gdf.drop('geometry', axis=1).to_csv('../data/overlay_issues/problematic.csv')\n",
    "problematic_gdf.to_parquet('../data/overlay_issues/problematic.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding indications for problematic geometries to the dataset for the overlay function to handle\n",
    "# They are found empirically in uk_gb_nfi_awi_overlap.ipynb (time to run: 4h)\n",
    "# Notes for 2022: Pickle Wood (461425) index has not been returned by the advanced algo but still might be relevant?\n",
    "# There are only so many unique ones however, looking at the map it's about 20-30 places in Wales\n",
    "# 1e+2 works for 2012, 2013, 2018\n",
    "# 1e+1 works for 2014, 2015, 2016, 2017, 2019\n",
    "# 1e-1 works for 2020, 2021, 2022\n",
    "\n",
    "dataset = {\n",
    "    2022: pd.DataFrame({'Indices': [469005, 537605, 561434, 604367], 'Tolerances': [1e-1]*4}),\n",
    "    2021: pd.DataFrame({'Indices': [102122, 377302, 472827, 551872], 'Tolerances': [1e-1]*4}),\n",
    "    2020: pd.DataFrame({'Indices': [101247, 376396, 376450, 471099, 548850], 'Tolerances': [1e-1]*5}),\n",
    "    2019: pd.DataFrame({'Indices': [95060, 106935, 108275, 110139, 121142, 122418, 376394, 519912], 'Tolerances': [1e+1]*8}),\n",
    "    2018: pd.DataFrame({'Indices': [90236, 90684, 93475, 101521, 101885, 104099, 109659, 122946, 127023, 357215, 357303, 357656, 364976, 365065], 'Tolerances': [1e+2]*14}),\n",
    "    2017: pd.DataFrame({'Indices': [91447, 103102, 104423, 106270, 117173, 118443, 362874, 363289, 369684, 505330], 'Tolerances': [1e+1]*10}),\n",
    "    2016: pd.DataFrame({'Indices': [91187, 102832, 104153, 105996, 116870, 118127, 360380, 360793, 367187, 500980], 'Tolerances': [1e+1]*10}),\n",
    "    2015: pd.DataFrame({'Indices': [13102, 13174, 17051, 17876, 67774, 68192, 68851, 84599, 107901, 108724], 'Tolerances': [1e+1]*10}),\n",
    "    2014: pd.DataFrame({'Indices': [13304, 13890, 16379, 17061, 70714, 71152, 76239, 92419, 117106, 125221], 'Tolerances': [1e+1]*10}),\n",
    "    2013: pd.DataFrame({'Indices': [12940, 13012, 16770, 17535, 72578, 72995, 73651, 86444, 118417, 119236, 122720], 'Tolerances': [1e+2]*11}),\n",
    "    2012: pd.DataFrame({'Indices': [525403, 525474, 529062, 529800, 550028, 555959, 556376, 557030, 569161, 569550, 570669], 'Tolerances': [1e+2]*11})\n",
    "}\n",
    "\n",
    "# Construct the desired structure\n",
    "nfi_dataset_problematic = {}\n",
    "\n",
    "for year, df in dataset.items():\n",
    "    nfi_dataset_problematic[year] = pd.DataFrame({\n",
    "        'Indices': df['Indices'].tolist(),\n",
    "        'Tolerances': df['Tolerances'].tolist()\n",
    "    })\n",
    "    nfi_dataset_problematic[year].to_csv(f'../data/overlay_issues/problematic_{year}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw output after 4h30m\n",
    "\n",
    "All of the geometries are in Wales, for every year.\n",
    "\n",
    "\n",
    "![A screenshot of the map with all problematic geometries](../assets/nfi_problematic_geometries.png)\n",
    "\n",
    "<details>\n",
    "    <summary>Expand for raw output first run</summary>\n",
    "\n",
    "{2022:    Indices Tolerance\n",
    " 0   469005      None\n",
    " 1   537605      None\n",
    " 2   561434      None,\n",
    " 2020:    Indices Tolerance\n",
    " 0   101247      None\n",
    " 1   376396      None\n",
    " 2   376450      None\n",
    " 3   471099      None,\n",
    " 2021:    Indices Tolerance\n",
    " 0   102122      None\n",
    " 1   377302      None\n",
    " 2   472827      None,\n",
    " 2012:    Indices Tolerance\n",
    " 0   525474      None\n",
    " 1   529062      None\n",
    " 2   529800      None\n",
    " 3   550028      None\n",
    " 4   555959      None\n",
    " 5   556376      None\n",
    " 6   557030      None\n",
    " 7   569161      None\n",
    " 8   569550      None\n",
    " 9   570669      None,\n",
    " 2013:    Indices Tolerance\n",
    " 0    13012      None\n",
    " 1    16770      None\n",
    " 2    17535      None\n",
    " 3    72578      None\n",
    " 4    72995      None\n",
    " 5    73651      None\n",
    " 6    86444      None\n",
    " 7   118417      None\n",
    " 8   119236      None\n",
    " 9   122720      None,\n",
    " 2014:    Indices Tolerance\n",
    " 0    13890      None\n",
    " 1    16379      None\n",
    " 2    17061      None\n",
    " 3    70714      None\n",
    " 4    71152      None\n",
    " 5    76239      None\n",
    " 6    92419      None\n",
    " 7   117106      None\n",
    " 8   125221      None,\n",
    " 2015:    Indices Tolerance\n",
    " 0    13174      None\n",
    " 1    17051      None\n",
    " 2    17876      None\n",
    " 3    67774      None\n",
    " 4    68192      None\n",
    " 5    68851      None\n",
    " 6    84599      None\n",
    " 7   107901      None\n",
    " 8   108724      None,\n",
    " 2016:    Indices Tolerance\n",
    " 0    91187      None\n",
    " 1   102832      None\n",
    " 2   104153      None\n",
    " 3   105996      None\n",
    " 4   116870      None\n",
    " 5   118127      None\n",
    " 6   360793      None\n",
    " 7   367187      None\n",
    " 8   500980      None,\n",
    " 2017:    Indices Tolerance\n",
    " 0    91447      None\n",
    " 1   103102      None\n",
    " 2   104423      None\n",
    " 3   106270      None\n",
    " 4   117173      None\n",
    " 5   118443      None\n",
    " 6   363289      None\n",
    " 7   369684      None\n",
    " 8   505330      None,\n",
    " 2018:     Indices Tolerance\n",
    " 0     90236      None\n",
    " 1     90684      None\n",
    " 2     93475      None\n",
    " 3    101521      None\n",
    " 4    101885      None\n",
    " 5    104099      None\n",
    " 6    109659      None\n",
    " 7    122946      None\n",
    " 8    127023      None\n",
    " 9    357215      None\n",
    " 10   357303      None\n",
    " 11   357656      None\n",
    " 12   364976      None\n",
    " 13   365065      None,\n",
    " 2019:    Indices Tolerance\n",
    " 0    95060      None\n",
    " 1   106935      None\n",
    " 2   108275      None\n",
    " 3   110139      None\n",
    " 4   121142      None\n",
    " 5   122418      None\n",
    " 6   376394      None\n",
    " 7   519912      None}\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary>Expand for raw output second run</summary>\n",
    "\n",
    "{2012:     Indices Tolerance\n",
    " 0    525403      None\n",
    " 1    525474      None\n",
    " 2    529062      None\n",
    " 3    529800      None\n",
    " 4    550028      None\n",
    " 5    555959      None\n",
    " 6    556376      None\n",
    " 7    557030      None\n",
    " 8    569161      None\n",
    " 9    569550      None\n",
    " 10   570669      None,\n",
    " 2013:     Indices Tolerance\n",
    " 0     12940      None\n",
    " 1     13012      None\n",
    " 2     16770      None\n",
    " 3     17535      None\n",
    " 4     72578      None\n",
    " 5     72995      None\n",
    " 6     73651      None\n",
    " 7     86444      None\n",
    " 8    118417      None\n",
    " 9    119236      None\n",
    " 10   122720      None,\n",
    " 2014:    Indices Tolerance\n",
    " 0    13304      None\n",
    " 1    13890      None\n",
    " 2    16379      None\n",
    " 3    17061      None\n",
    " 4    70714      None\n",
    " 5    71152      None\n",
    " 6    76239      None\n",
    " 7    92419      None\n",
    " 8   117106      None\n",
    " 9   125221      None,\n",
    " 2015:    Indices Tolerance\n",
    " 0    13102      None\n",
    " 1    13174      None\n",
    " 2    17051      None\n",
    " 3    17876      None\n",
    " 4    67774      None\n",
    " 5    68192      None\n",
    " 6    68851      None\n",
    " 7    84599      None\n",
    " 8   107901      None\n",
    " 9   108724      None,\n",
    " 2016:    Indices Tolerance\n",
    " 0    91187      None\n",
    " 1   102832      None\n",
    " 2   104153      None\n",
    " 3   105996      None\n",
    " 4   116870      None\n",
    " 5   118127      None\n",
    " 6   360380      None\n",
    " 7   360793      None\n",
    " 8   367187      None\n",
    " 9   500980      None,\n",
    " 2017:    Indices Tolerance\n",
    " 0    91447      None\n",
    " 1   103102      None\n",
    " 2   104423      None\n",
    " 3   106270      None\n",
    " 4   117173      None\n",
    " 5   118443      None\n",
    " 6   362874      None\n",
    " 7   363289      None\n",
    " 8   369684      None\n",
    " 9   505330      None,\n",
    " 2018:     Indices Tolerance\n",
    " 0     90236      None\n",
    " 1     90684      None\n",
    " 2     93475      None\n",
    " 3    101521      None\n",
    " 4    101885      None\n",
    " 5    104099      None\n",
    " 6    109659      None\n",
    " 7    122946      None\n",
    " 8    127023      None\n",
    " 9    357215      None\n",
    " 10   357303      None\n",
    " 11   357656      None\n",
    " 12   364976      None\n",
    " 13   365065      None,\n",
    " 2019:    Indices Tolerance\n",
    " 0    95060      None\n",
    " 1   106935      None\n",
    " 2   108275      None\n",
    " 3   110139      None\n",
    " 4   121142      None\n",
    " 5   122418      None\n",
    " 6   376394      None\n",
    " 7   519912      None,\n",
    " 2020:    Indices Tolerance\n",
    " 0   101247      None\n",
    " 1   376396      None\n",
    " 2   376450      None\n",
    " 3   548850      None,\n",
    " 2021:    Indices Tolerance\n",
    " 0   102122      None\n",
    " 1   377302      None\n",
    " 2   551872      None,\n",
    " 2022:    Indices Tolerance\n",
    " 0   469005      None\n",
    " 1   537605      None\n",
    " 2   604367      None}\n",
    "</details>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
