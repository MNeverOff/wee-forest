{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlaying NFI and AWI datasets\n",
    "\n",
    "With both NFI and AWI data being available in geospatial format it's possible to subtract one from the other, giving us a relatively accurate impression of Trees that are native, not native and felled within the woodlands, making for a great map for the public to see.\n",
    "\n",
    "### Approach\n",
    "\n",
    "Below we'll make use of the AWI dataset we have created and processed in [AWI workflow](uk_gb_awi.ipynb) and the existing NFI datasets to create a combined dataset, showing:\n",
    "\n",
    "- Native Trees. These are areas from the AWI dataset, minus any overlap with NFI's \"Felled\" areas.\n",
    "- Non-Native Trees. Areas from the NFI dataset designated as \"Trees\" minus the AWI overlap.\n",
    "- Felled Trees. Areas from the NFI dataset designated as \"Barren & Felled\" minus the AWI overlap.\n",
    "- Felled Native Trees. Areas from the NFI dataset not designated as \"Trees\" that overlap with the AWI dataset.\n",
    "- Other NFI. Areas from the NFI dataset designated as \"Other\" minus the AWI overlap.\n",
    "\n",
    "### Overlaying Errors\n",
    "\n",
    "Certain geometries in the NFI dataset could trigger a nasty `found non-noded intersection` error when running gpd.overlay with `difference` parameter. It's unclear what causes it, but the recommended solutions like `buffer(0)` do not work. In total there are 97 entries like this in the NFI dataset, all of them located in Wales. I started my initial troubleshooting with 2022 and found 4 places, 3 in `Trees` and 1 in `Barren & Felled`. \n",
    "\n",
    "The collection called `nfi_dataset_problematic` is the end result of work across multiple datasets that's intended to be reused once the process is over so it doesn't have to be repeated, as it easily takes around 20 minutes per year for a total of 4 hours. The indexes stored in the collection should be consistent across restarts but might not be if you have changed the functions creating the initial `nfi_dataset`, but the source_index generated and read remedies that.\n",
    "\n",
    "### Notes\n",
    "\n",
    "All runtimes are indicated for Apple M1 Max 64GB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "gpd.options.io_engine = 'pyogrio'\n",
    "\n",
    "import util.geo_ops as gops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the AWI dataset from parquet\n",
    "# Runtime: 2s, RAM: 1.5GB\n",
    "awi_dataset = gpd.read_parquet('../data/processed/gb_awi_dataset.parquet')\n",
    "\n",
    "gops.geodf_summary(awi_dataset, 'type_combined', 'area_ha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_datasets(left_df, right_df,  problematic_indices=None, overlay_operation='difference'):\n",
    "    # Copy to avoid modifying the original DataFrame\n",
    "    ldf = left_df.copy()\n",
    "    rdf = right_df.copy()\n",
    "\n",
    "    # Simplify the geometries of the problematic indices if any\n",
    "    if problematic_indices is not None:\n",
    "        for idx, row in problematic_indices.iterrows():\n",
    "            if row['Indices'] in ldf.index:\n",
    "                ldf.loc[row['Indices'], 'geometry'] = ldf.loc[row['Indices'], 'geometry'].simplify(row['Tolerances'])\n",
    "\n",
    "    # Use overlay to find the geometries in left_df_crs that do not intersect with right_df_crs\n",
    "    overlay = gpd.overlay(ldf, rdf, how=overlay_operation, keep_geom_type=False)\n",
    "\n",
    "    # Calculate the area of each geometry in the difference and store it in a new column\n",
    "    overlay['area_ha'] = overlay.geometry.area / 10000\n",
    "\n",
    "    return overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the final, main dataset with overlay, combined, aggregate and source data preserved across all years\n",
    "# Runtime 1h 10m, ~6m per year for 11 years, RAM: 12GB Max\n",
    "\n",
    "summaries = {}\n",
    "\n",
    "for year in range(2012, 2023):\n",
    "    # Getting the NFI dataset\n",
    "    print(f'Started processing year {year}.')\n",
    "    nfi_dataset = gpd.read_parquet(f'../data/processed/gb_nfi_dataset_{year}.parquet')\n",
    "\n",
    "    # And the problematic indices calculated in the _errors notebook\n",
    "    nfi_dataset_problematic = pd.read_csv(f'../data/overlay_issues/problematic_{year}.csv')\n",
    "\n",
    "    # Ensuring matching CRS\n",
    "    awi_dataset = awi_dataset.to_crs(epsg=27700)\n",
    "    nfi_dataset = nfi_dataset.to_crs(epsg=27700)\n",
    "    print(f'Finished aligning CRS for {year}.')\n",
    "\n",
    "    # Native trees as difference between AWI Trees and NFI Felled & Other\n",
    "    awi_dataset_nfi_intact = overlay_datasets(awi_dataset[awi_dataset.type_combined != 'Other (land, pasture, unknown, etc.)'], nfi_dataset[nfi_dataset.type_combined != 'Trees'], problematic_indices=nfi_dataset_problematic, overlay_operation='difference')\n",
    "\n",
    "    # Non-native trees as difference between NFI \"Trees\" and AWI as a whole\n",
    "    nfi_dataset_non_awi = overlay_datasets(nfi_dataset[nfi_dataset.type_combined == 'Trees'], awi_dataset, problematic_indices=nfi_dataset_problematic, overlay_operation='difference')\n",
    "\n",
    "    # Native Felled Trees as intersection between AWI Trees and NFI Felled & Other\n",
    "    awi_dataset_nfi_felled = overlay_datasets(awi_dataset[awi_dataset.type_combined != 'Other (land, pasture, unknown, etc.)'], nfi_dataset[nfi_dataset.type_combined != 'Trees'], problematic_indices=nfi_dataset_problematic, overlay_operation='intersection')\n",
    "\n",
    "    # General Felled Trees as NFI Felled less all AWI\n",
    "    nfi_dataset_felled_non_awi = overlay_datasets(nfi_dataset[nfi_dataset.type_combined == 'Barren & Felled'], awi_dataset, problematic_indices=nfi_dataset_problematic, overlay_operation='difference')\n",
    "\n",
    "    # Other NFI as NFI without AWI at all\n",
    "    nfi_dataset_other_awi = overlay_datasets(nfi_dataset[nfi_dataset.type_combined == 'Other (land, urban, etc.)'], awi_dataset, problematic_indices=nfi_dataset_problematic, overlay_operation='difference')\n",
    "\n",
    "    # Other AWI is simply a subset\n",
    "    awi_other = awi_dataset[awi_dataset.type_combined == 'Other (land, pasture, unknown, etc.)']\n",
    "\n",
    "    # Validation sets\n",
    "    nfi_x_awi = overlay_datasets(nfi_dataset, awi_dataset, problematic_indices=nfi_dataset_problematic, overlay_operation='intersection')\n",
    "    \n",
    "    print(f\"Native Trees: {format(round(awi_dataset_nfi_intact.area_ha.sum(), 2), ',.2f')} ha\")\n",
    "    print(f\"Non-Native Trees: {format(round(nfi_dataset_non_awi.area_ha.sum(), 2), ',.2f')} ha\")\n",
    "    print(f\"Native Felled Trees: {format(round(awi_dataset_nfi_felled.area_ha.sum(), 2), ',.2f')} ha\")\n",
    "    print(f\"Other Felled Trees: {format(round(nfi_dataset_felled_non_awi.area_ha.sum(), 2), ',.2f')} ha\")\n",
    "    print(f\"Other NFI areas: {format(round(nfi_dataset_other_awi.area_ha.sum(), 2), ',.2f')} ha\")\n",
    "    print(f\"Other AWI areas: {format(round(awi_dataset_nfi_intact.area_ha.sum(), 2), ',.2f')} ha\")\n",
    "    print(f\"Total non-unique in both: {format(round(awi_dataset.area_ha.sum() + nfi_dataset.area_ha.sum(), 2), ',.2f')} ha\")\n",
    "    print(f\"Total intersection between datasets: {format(round(nfi_x_awi.area_ha.sum(), 2), ',.2f')} ha\")\n",
    "    print(f\"Total unique across both datasets: {format(round(awi_dataset.area_ha.sum() + nfi_dataset.area_ha.sum() - nfi_x_awi.area_ha.sum(), 2), ',.2f')} ha\")\n",
    "\n",
    "    nfi_awi_combined = {}\n",
    "\n",
    "    native_trees_ds = awi_dataset_nfi_intact\n",
    "    nfi_awi_combined['Native Trees'] = gpd.GeoDataFrame({\n",
    "        'source_index': native_trees_ds['source_index'],\n",
    "        'type_overlay': 'Native Trees',\n",
    "        'type_combined': native_trees_ds['type_combined'],\n",
    "        'type_aggregate': native_trees_ds['type_aggregate'],\n",
    "        'type_source': native_trees_ds['type_source'],\n",
    "        'area_ha': native_trees_ds['area_ha'],\n",
    "    }, geometry=native_trees_ds.geometry, crs=native_trees_ds.crs)\n",
    "\n",
    "    non_native_trees_ds = nfi_dataset_non_awi\n",
    "    nfi_awi_combined['Non-Native Trees'] = gpd.GeoDataFrame({\n",
    "        'source_index': non_native_trees_ds['source_index'],\n",
    "        'type_overlay': 'Non-Native Trees',\n",
    "        'type_combined': non_native_trees_ds['type_combined'],\n",
    "        'type_aggregate': non_native_trees_ds['type_aggregate'],\n",
    "        'type_source': non_native_trees_ds['type_source'],\n",
    "        'area_ha': non_native_trees_ds['area_ha'],\n",
    "    }, geometry=non_native_trees_ds.geometry, crs=non_native_trees_ds.crs)\n",
    "\n",
    "    # Taking the right areas to show to which areas the Native Woodland has been lost\n",
    "    felled_native_trees_ds = awi_dataset_nfi_felled\n",
    "    nfi_awi_combined['Felled Native Trees'] = gpd.GeoDataFrame({\n",
    "        'source_index': felled_native_trees_ds['source_index_2'],\n",
    "        'type_overlay': 'Felled Native Trees',\n",
    "        'type_combined': felled_native_trees_ds['type_combined_2'],\n",
    "        'type_aggregate': felled_native_trees_ds['type_aggregate_2'],\n",
    "        'type_source': felled_native_trees_ds['type_source_2'],\n",
    "        'area_ha': felled_native_trees_ds['area_ha'],\n",
    "    }, geometry=felled_native_trees_ds.geometry, crs=felled_native_trees_ds.crs)\n",
    "\n",
    "    felled_trees_ds = nfi_dataset_felled_non_awi\n",
    "    nfi_awi_combined['Other Felled Trees'] = gpd.GeoDataFrame({\n",
    "        'source_index': felled_trees_ds['source_index'],\n",
    "        'type_overlay': 'Other Felled Trees',\n",
    "        'type_combined': felled_trees_ds['type_combined'],\n",
    "        'type_aggregate': felled_trees_ds['type_aggregate'],\n",
    "        'type_source': felled_trees_ds['type_source'],\n",
    "        'area_ha': felled_trees_ds['area_ha'],\n",
    "    }, geometry=felled_trees_ds.geometry, crs=felled_trees_ds.crs)\n",
    "\n",
    "    other_ds = pd.concat([nfi_dataset_other_awi, awi_other])\n",
    "    nfi_awi_combined['Other (land, pasture, urban, etc.)'] = gpd.GeoDataFrame({\n",
    "        'source_index': other_ds['source_index'],\n",
    "        'type_overlay': 'Other (land, pasture, urban, etc.)',\n",
    "        'type_combined': other_ds['type_combined'],\n",
    "        'type_aggregate': other_ds['type_aggregate'],\n",
    "        'type_source': other_ds['type_source'],\n",
    "        'area_ha': other_ds['area_ha'],\n",
    "    }, geometry=other_ds.geometry, crs=other_ds.crs)\n",
    "\n",
    "    gb_nfi_awi_overlay = pd.concat(nfi_awi_combined.values(), ignore_index=True)\n",
    "    print(f\"Sum of overlay features: {format(round(gb_nfi_awi_overlay.area_ha.sum(), 2), ',.2f')} ha\")\n",
    "    gb_nfi_awi_overlay.to_parquet(f'../data/processed/gb_nfi_awi_overlay_{year}.parquet')\n",
    "\n",
    "    print(f'Finished processing for {year}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Writing out the summary CSVs. This can be performed gradually as the data is processed as well for much lower RAM cost\n",
    "# Runtime: 1m30s, RAM: 40GB\n",
    "gb_nfi_awi_overlay = {}\n",
    "\n",
    "for year in range(2012, 2023):\n",
    "    gb_nfi_awi_overlay[year] = gpd.read_parquet(f'../data/processed/gb_nfi_awi_overlay_{year}.parquet')\n",
    "\n",
    "types = ['source', 'aggregate', 'combined', 'overlay']\n",
    "for type in types:\n",
    "    gops.geodfs_to_csv(gb_nfi_awi_overlay, f'./sheets/gb_nfi_awi_{type}_summary.csv', f'type_{type}', 'area_ha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting the datasets freeing up memory\n",
    "del nfi_dataset\n",
    "del awi_dataset\n",
    "del nfi_dataset_problematic\n",
    "del gb_nfi_awi_overlay\n",
    "del native_trees_ds\n",
    "del non_native_trees_ds\n",
    "del felled_trees_ds\n",
    "del felled_native_trees_ds\n",
    "del other_ds\n",
    "del awi_other\n",
    "del nfi_dataset_non_awi\n",
    "del nfi_dataset_other_awi\n",
    "del awi_dataset_nfi_intact\n",
    "del awi_dataset_nfi_felled\n",
    "del nfi_dataset_felled_non_awi\n",
    "del nfi_awi_combined\n",
    "del nfi_x_awi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
